\section{Introduction}
\begin{itemize}
\item Importance of quantification of MRI in understanding healthy brain development\cite{giedd1999brain}, brain-behavior relationships\cite{biswal2010toward} and diseases, such as multiple sclerosis\cite{bakshi2008mri}, 
\item Large diversity of people, their brains, both normally and from disease, means we need to collect large datasets = "big data"
\item To comprehend all the data we collect, we reduce 3D or 4D images that are rich with information to 1D scalar "features", such as "brain size" with automated algorithms
\item But automated algorithms don't have the rich visual system of humans, they make errors, especially for brains with pathology or early in development
\item Data science can help with biomedical/clinical research by transforming a research question into a crowd-sourced solution. 
\item Crowd sourcing has been successful in many other disciplines \cite{wiggins2011conservation}, including mathematics \cite{cranshaw2011polymath}, astronomy \cite{lintott2008galaxy}, biochemistry\cite{eiben2012increased}, and neuroscience\cite{kim2014space}, where "citizen-neurocientists" helped identify neuronal connections in a mouse retina, through the Eyewire game. 
\item The eyewire paradigm broke large 3D images into small cubes, where users were asked to identify and color neurons. They got over 200,000 users from 145 different countries.
\item resulted in an understanding of how mammalian retinal cells detect motion.
\item How can this paradigm transfer to neuroimaging? this is an example of the "microtask" paradigm, which gives access to a large user pool to collect data and reward participants by reputation (via gamification) or  by micro-payments (amazon turk) \cite{kittur2008crowdsourcing}.
\item I propose an open platform that can be adapted to different use cases around the following core concepts/specific aims.
\end{itemize}

\section{Specific Aims}
\begin{enumerate}
\item Scaleablity and Security: A database system and server backend that keeps data private by piece-wise exposure
\item Learning by Example: Machine learning tool that learns from human curation
\item Training and Gamification: User interface that trains users to solve a specific problem to solve, and keeps them engaged to keep solving
\\
\\
The system I propose can be generalized to many use cases, including MS lesion segmentation, but for this proposal, these aims will be applied to a specific use case, which is brain extraction. Brain extraction is important because brain volume is an important feature to study in human development and aging, but also in diseases like MS, and in genotype-phenotype studies, where precision is important due to small effect sizes. Brain extraction is difficult for a computer alone the intensity of the dura looks similar to that of gray matter, and often require manual editing, as described in the Freesurfer package. The data used in this proposal will be open-source data, but the platform can accommodate private data as well, due to aim 1. 

\end{enumerate}

\section{Specific Aim 1: Scaleablility and Security}

We will address 2 key challenges:
\begin{itemize}
\item data management, handling large datasets, distributed computing 
\begin{itemize}
\item need to learn how to use Amazon, spark, distributed computing
\item learn how to connect to amazon turk for paid incentive, zooniverse for free
\end{itemize}
\item serving piece-wise "chunks" of data rather than the whole dataset. This preserves privacy if the data is not open, and reduces the fatigue of users. Need to serve intelligently to figure out which pieces to serve next.
\begin{itemize}
\item different datasets will need to be chunked differently. Lesions need all 3 slices view but brain mask editing, only 1. Needs to be user-specified, to answer the question "how much chunking is necessary for this application"
\end{itemize}
\end{itemize}

\section{Specific Aim 2: Learning by Example}

Address 2 challenges:
\begin{itemize}
\item resolving user input to create a final image, based on training data
\begin{itemize}
\item create a probability image weighted by how well each user did on the training data
\end{itemize}
\item predicting regions of variability to serve more efficiently
\begin{itemize}
\item can we predict which voxels are "controversial" and only show those?
\end{itemize}
\end{itemize}

\section{Specific Aim 3: Training and Gamification}
\begin{itemize}
\item training: how frequently does training data need to be used
\begin{itemize}
\item need to signal to users that this is being verified, avoid malicious users, increase time and care spent on task
\item also keep track of time spent on task. If many voxels were erased, were they erased quickly or slowly. 
\end{itemize}
\item UI edit, gamify
\begin{itemize}
\item already have mindcontrol platform to do editing
\item give badges relative to volume of voxels edited, reward training with points for feedback
\item use amazon turk's api rather than the turk platform itself. 
\end{itemize}
\end{itemize}