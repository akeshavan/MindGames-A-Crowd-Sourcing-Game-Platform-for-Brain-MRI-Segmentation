\section{Introduction}

Advancements in neuroimaging technology have enabled researchers to begin to understand the mechanisms of healthy brain development \cite{giedd1999brain} and brain pathologies, such as multiple sclerosis \cite{bakshi2008mri}. Due to the large heterogeneity of brain morphology, increasingly large sample sizes are needed to answer biomedical/clinical questions. In order to make sense of all the information, automated algorithms were developed to reduce information-rich 3D MRI images to 1 dimensional summary metrics that are easy to understand. However, because automated algorithms don't have the advanced visual system of humans, they make systematic errors, especially for brains with pathology or early in development. I think that data science can help answer neuroscience research questions using a crowd-sourced strategy.

Crowd sourcing has been successful in many other disciplines \cite{wiggins2011conservation}, including mathematics \cite{cranshaw2011polymath}, astronomy \cite{lintott2008galaxy}, biochemistry\cite{eiben2012increased}, and neuroscience\cite{kim2014space}, where "citizen-neurocientists" helped identify neuronal connections in a mouse retina, through the Eyewire game. 

\begin{itemize}
\item Crowd sourcing has been successful in many other disciplines \cite{wiggins2011conservation}, including mathematics \cite{cranshaw2011polymath}, astronomy \cite{lintott2008galaxy}, biochemistry\cite{eiben2012increased}, and neuroscience\cite{kim2014space}, where "citizen-neurocientists" helped identify neuronal connections in a mouse retina, through the Eyewire game. 
\item The eyewire paradigm broke large 3D images into small cubes, where users (non-experts) were trained to identify and color neurons. They got over 200,000 users from 145 different countries.
\item resulted in an understanding of how mammalian retinal cells detect motion.
\item How can this paradigm transfer to neuroimaging? With 3 key features of the eyewire paradigm: 1) training with gamification, 2) machine learning to help and 3) microtasks. this is an example of the "microtask" paradigm, which gives access to a large user pool of non-experts to collect data and reward participants by reputation (via gamification) or  by micro-payments (amazon turk) \cite{kittur2008crowdsourcing}.
\item I propose an open platform that can be adapted to multiple use-cases, particularly, different tissue classification applications, such as brain extraction, and lesion segmentation. 
\end{itemize}

\section{Specific Aims}
\begin{enumerate}
\item Scaleablity and Security: A scaleable database system and server backend that keeps data private by piece-wise exposure
\item Learning by Example: Machine learning tool that learns from human curation
\item Training and Gamification: User interface that trains users to solve a specific problem to solve, and keeps them engaged to keep solving
\\
\\
The system I propose can be generalized to many use cases, including MS lesion segmentation, but for this proposal, these aims will be applied to a specific use case, which is brain extraction. Brain extraction is important because brain volume is an important feature to study in human development and aging, but also in diseases like MS, and in genotype-phenotype studies, where precision is important due to small effect sizes. Brain extraction is difficult for a computer alone the intensity of the dura looks similar to that of gray matter, and often require manual editing, as described in the Freesurfer package. The data used in this proposal will be open-source data, but the platform can accommodate private data as well, due to aim 1. 

\end{enumerate}

\section{Specific Aim 1: Scaleablility and Security}
EyeWire game had over 200,000 users, so our solution needs to scale well. 
We will address 2 key challenges:
\begin{itemize}
\item data management, handling large datasets, distributed computing 
\begin{itemize}
\item need to learn how to use Amazon, spark, distributed computing. Resources at the eScience institute will help. 
\item learn how to connect to amazon turk for paid incentive, zooniverse for free
\end{itemize}
\item serving piece-wise "chunks" of data rather than the whole dataset. This preserves privacy if the data is not open, and reduces the fatigue of users. Need to serve intelligently to figure out which pieces to serve next.
\item show different views: axial, coronal, sagittal
\begin{itemize}
\item different datasets will need to be chunked differently. Lesions need all 3 slices view but brain mask editing, only 1. Needs to be user-specified, to answer the question "how much chunking is necessary for this application"
\end{itemize}
\end{itemize}

\section{Specific Aim 2: Learning by Example}

Address 2 challenges:
\begin{itemize}
\item resolving user input to create a final image, based on training data
\begin{itemize}
\item create a probability image weighted by how well each user did on the training data
\item joint fusion strategy?
\end{itemize}
\item predicting regions of variability to serve more efficiently
\begin{itemize}
\item can we predict which voxels are "controversial" and only show those?
\end{itemize}
\end{itemize}

\section{Specific Aim 3: Training and Gamification}
\begin{itemize}
\item training: how frequently does training data need to be used
\begin{itemize}
\item need to signal to users that this is being verified, avoid malicious users, increase time and care spent on task
\item also keep track of time spent on task. If many voxels were erased, were they erased quickly or slowly. 
\end{itemize}
\item UI edit, gamify
\begin{itemize}
\item already have mindcontrol platform to do editing
\item give badges relative to volume of voxels edited, reward training with points for feedback
\item use amazon turk's api rather than the turk platform itself. 
\end{itemize}
\end{itemize}